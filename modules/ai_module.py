"""
AI Module - Reinforcement Learning Policy

Chloe Lee (cl4490) ë‹´ë‹¹ ëª¨ë“ˆ
PPO/DQN ê¸°ë°˜ ê²Œì„ AI ì •ì±…

ë‚œì´ë„ ë ˆë²¨ ì‹œìŠ¤í…œ:
- Level 1 (Easy): ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± (ê¸°ë³¸ íšŒí”¼ë§Œ)
- Level 2 (Medium): PPO ëª¨ë¸ ê¸°ë°˜ (Vision â†’ State â†’ Policy)
- Level 3 (Hard): ê³ ê¸‰ íœ´ë¦¬ìŠ¤í‹± + PPO ì•™ìƒë¸”
- Level 4 (Expert): í’€ ì•™ìƒë¸” (PPO + DQN + íœ´ë¦¬ìŠ¤í‹±)

ìˆ˜ì •: 2025-11-29
- Level 2ì— ì‹¤ì œ PPO ëª¨ë¸ í†µí•©
- state_encoder.py ì‚¬ìš©
"""

import numpy as np
from typing import Dict, List, Tuple, Optional, Any
import time
import random
from pathlib import Path

# PyTorch
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    print("âš ï¸ PyTorch ì—†ìŒ - íœ´ë¦¬ìŠ¤í‹± ëª¨ë“œë§Œ ì‚¬ìš© ê°€ëŠ¥")

# State Encoder (ìš°ë¦¬ê°€ ë§Œë“  ëª¨ë“ˆ)
try:
    from .state_encoder import encode_state, game_state_to_detections, STATE_DIM, ACTION_LIST
except ImportError:
    try:
        from state_encoder import encode_state, game_state_to_detections, STATE_DIM, ACTION_LIST
    except ImportError:
        print("âš ï¸ state_encoder.py ì—†ìŒ - íœ´ë¦¬ìŠ¤í‹± ëª¨ë“œë§Œ ì‚¬ìš© ê°€ëŠ¥")
        STATE_DIM = 26
        ACTION_LIST = ["stay", "left", "right", "jump"]
        encode_state = None
        game_state_to_detections = None


# ============================================================================
# Policy Network (PPOìš©)
# ============================================================================

class PolicyNetwork(nn.Module):
    """
    Actor Network: State â†’ Action Probabilities
    
    Architecture: 26 â†’ 256 â†’ 256 â†’ 128 â†’ 4
    """
    
    def __init__(self, state_dim=26, action_dim=4, hidden_dim=256):
        super(PolicyNetwork, self).__init__()
        self.fc1 = nn.Linear(state_dim, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, hidden_dim)
        self.fc3 = nn.Linear(hidden_dim, hidden_dim // 2)
        self.fc4 = nn.Linear(hidden_dim // 2, action_dim)
        
        # Xavier ì´ˆê¸°í™”
        nn.init.xavier_uniform_(self.fc1.weight)
        nn.init.xavier_uniform_(self.fc2.weight)
        nn.init.xavier_uniform_(self.fc3.weight)
        nn.init.xavier_uniform_(self.fc4.weight)
        
    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = F.relu(self.fc3(x))
        x = self.fc4(x)
        return F.softmax(x, dim=-1)


class ValueNetwork(nn.Module):
    """
    Critic Network: State â†’ Value Estimate
    """
    
    def __init__(self, state_dim=26, hidden_dim=256):
        super(ValueNetwork, self).__init__()
        self.fc1 = nn.Linear(state_dim, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, hidden_dim)
        self.fc3 = nn.Linear(hidden_dim, hidden_dim // 2)
        self.fc4 = nn.Linear(hidden_dim // 2, 1)
        
    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = F.relu(self.fc3(x))
        return self.fc4(x)


# ============================================================================
# AI Strategy Classes
# ============================================================================

class AIStrategy:
    """AI ì „ëµ ë² ì´ìŠ¤ í´ë˜ìŠ¤"""
    
    def __init__(self, level: int, name: str):
        self.level = level
        self.name = name
    
    def make_decision(self, game_state: Dict[str, Any]) -> Optional[str]:
        raise NotImplementedError


class Level1Strategy(AIStrategy):
    """
    Level 1 (Easy) - ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±
    
    ì „ëµ:
    - ê¸°ë³¸ì ì¸ ë©”í…Œì˜¤ íšŒí”¼ë§Œ
    - ë³„ì€ ë¬´ì‹œ
    """
    
    def __init__(self):
        super().__init__(level=1, name="Easy")
        self.DETECTION_RANGE = 200
        self.DANGER_RANGE = 100
    
    def make_decision(self, game_state: Dict[str, Any]) -> Optional[str]:
        player = game_state.get('player', {})
        obstacles = game_state.get('obstacles', [])
        
        player_x = player.get('x', 480)
        player_y = player.get('y', 360)
        player_size = player.get('size', 50)
        player_center_x = player_x + player_size / 2
        
        # ê°€ì¥ ê°€ê¹Œìš´ ë©”í…Œì˜¤ ì°¾ê¸°
        nearest_meteor = None
        nearest_dist = float('inf')
        
        for obs in obstacles:
            if obs.get('type') != 'meteor':
                continue
            
            obs_x = obs.get('x', 0)
            obs_y = obs.get('y', 0)
            obs_size = obs.get('size', 50)
            obs_center_x = obs_x + obs_size / 2
            
            if obs_y < player_y:
                x_overlap = abs(player_center_x - obs_center_x) < self.DETECTION_RANGE
                if x_overlap:
                    dist = abs(player_center_x - obs_center_x) + (player_y - obs_y) * 0.5
                    if dist < nearest_dist:
                        nearest_dist = dist
                        nearest_meteor = obs
        
        # ë©”í…Œì˜¤ íšŒí”¼
        if nearest_meteor and nearest_dist < self.DANGER_RANGE:
            meteor_center_x = nearest_meteor['x'] + nearest_meteor.get('size', 50) / 2
            if meteor_center_x < player_center_x:
                return 'right'
            else:
                return 'left'
        
        return None


class Level2Strategy(AIStrategy):
    """
    Level 2 (Medium) - PPO ëª¨ë¸ ê¸°ë°˜
    
    ì „ëµ:
    - í•™ìŠµëœ PPO ëª¨ë¸ ì‚¬ìš©
    - state_encoderë¡œ ê²Œì„ ìƒíƒœ â†’ 26-dim ë²¡í„° ë³€í™˜
    - ëª¨ë¸ ì—†ìœ¼ë©´ íœ´ë¦¬ìŠ¤í‹± í´ë°±
    """
    
    def __init__(self, model_path: Optional[str] = None):
        super().__init__(level=2, name="Medium (PPO)")
        self.model_path = model_path
        self.policy_net = None
        self.device = None
        self.fallback_strategy = Level1Strategy()
        
        # PPO ëª¨ë¸ ë¡œë“œ
        self._load_ppo_model()
    
    def _load_ppo_model(self):
        """PPO ëª¨ë¸ ë¡œë“œ"""
        if not TORCH_AVAILABLE:
            print("âš ï¸ Level 2: PyTorch ì—†ìŒ, íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ í´ë°±")
            return
        
        if not self.model_path:
            print("âš ï¸ Level 2: ëª¨ë¸ ê²½ë¡œ ì—†ìŒ, íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ í´ë°±")
            return
        
        try:
            model_file = Path(self.model_path)
            if not model_file.exists():
                print(f"âš ï¸ Level 2: ëª¨ë¸ íŒŒì¼ ì—†ìŒ ({self.model_path})")
                return
            
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            
            # Checkpoint ë¡œë“œ
            checkpoint = torch.load(self.model_path, map_location=self.device)
            
            # State/Action ì°¨ì› í™•ì¸
            state_dim = checkpoint.get('state_dim', STATE_DIM)
            action_dim = checkpoint.get('action_dim', len(ACTION_LIST))
            
            # Policy Network ìƒì„± ë° ê°€ì¤‘ì¹˜ ë¡œë“œ
            self.policy_net = PolicyNetwork(state_dim, action_dim).to(self.device)
            
            if 'policy_state_dict' in checkpoint:
                self.policy_net.load_state_dict(checkpoint['policy_state_dict'])
            elif 'policy' in checkpoint:
                self.policy_net.load_state_dict(checkpoint['policy'])
            else:
                # ì§ì ‘ state_dictì¸ ê²½ìš°
                self.policy_net.load_state_dict(checkpoint)
            
            self.policy_net.eval()
            print(f"âœ… Level 2: PPO ëª¨ë¸ ë¡œë“œ ì„±ê³µ ({self.model_path})")
            print(f"   State dim: {state_dim}, Action dim: {action_dim}")
            
        except Exception as e:
            print(f"âš ï¸ Level 2: PPO ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ({e})")
            self.policy_net = None
    
    def make_decision(self, game_state: Dict[str, Any]) -> Optional[str]:
        """PPO ëª¨ë¸ ê¸°ë°˜ ì˜ì‚¬ê²°ì •"""
        # PPO ëª¨ë¸ì´ ìˆìœ¼ë©´ ì‚¬ìš©
        if self.policy_net is not None and encode_state is not None:
            try:
                return self._ppo_decision(game_state)
            except Exception as e:
                print(f"âš ï¸ Level 2: PPO ì¶”ë¡  ì˜¤ë¥˜ ({e})")
        
        # í´ë°±: Level 1 ì „ëµ ì‚¬ìš©
        return self.fallback_strategy.make_decision(game_state)
    
    def _ppo_decision(self, game_state: Dict[str, Any]) -> Optional[str]:
        """
        PPO ëª¨ë¸ ê¸°ë°˜ ì˜ì‚¬ê²°ì •
        
        1. game_state â†’ detections ë³€í™˜
        2. detections â†’ 26-dim state vector
        3. PPO ì¶”ë¡  â†’ action probabilities
        4. argmax â†’ action
        """
        # Step 1: game_state â†’ detections ë³€í™˜
        detections = game_state_to_detections(game_state)
        
        # Step 2: encode_state()ë¡œ 26-dim ë²¡í„° ìƒì„±
        state_vec = encode_state(detections, game_state)
        
        # Step 3: PPO ì¶”ë¡ 
        with torch.no_grad():
            state_tensor = torch.FloatTensor(state_vec).unsqueeze(0).to(self.device)
            action_probs = self.policy_net(state_tensor)
            action_idx = torch.argmax(action_probs, dim=-1).item()
        
        # Step 4: action index â†’ action string
        action = ACTION_LIST[action_idx]
        
        # 'stay'ëŠ” Noneìœ¼ë¡œ ë°˜í™˜ (app.py í˜¸í™˜)
        if action == 'stay':
            return None
        
        return action


class Level3Strategy(AIStrategy):
    """
    Level 3 (Hard) - ê³ ê¸‰ íœ´ë¦¬ìŠ¤í‹± + PPO
    
    ì „ëµ:
    - PPO ëª¨ë¸ + íœ´ë¦¬ìŠ¤í‹± ë³´ì™„
    - ìš©ì•” íšŒí”¼ ë¡œì§ ì¶”ê°€
    - ë³„ ìˆ˜ì§‘ ì „ëµ
    """
    
    def __init__(self, model_path: Optional[str] = None):
        super().__init__(level=3, name="Hard")
        self.ppo_strategy = Level2Strategy(model_path=model_path)
        self.METEOR_DANGER_RANGE = 150
        self.STAR_COLLECT_RANGE = 200
        self.EMERGENCY_RANGE = 80
    
    def make_decision(self, game_state: Dict[str, Any]) -> Optional[str]:
        """PPO + íœ´ë¦¬ìŠ¤í‹± ì•™ìƒë¸”"""
        player = game_state.get('player', {})
        obstacles = game_state.get('obstacles', [])
        lava = game_state.get('lava', {})
        
        player_x = player.get('x', 480)
        player_y = player.get('y', 360)
        player_size = player.get('size', 50)
        player_center_x = player_x + player_size / 2
        
        WIDTH = 960
        HEIGHT = 720
        
        # ê¸´ê¸‰ ìƒí™© ì²´í¬: ë©”í…Œì˜¤ê°€ ë§¤ìš° ê°€ê¹Œì›€
        for obs in obstacles:
            if obs.get('type') != 'meteor':
                continue
            obs_x = obs.get('x', 0)
            obs_y = obs.get('y', 0)
            obs_size = obs.get('size', 50)
            obs_center_x = obs_x + obs_size / 2
            
            dist = np.sqrt((player_center_x - obs_center_x)**2 + (player_y - obs_y)**2)
            if dist < self.EMERGENCY_RANGE and obs_y < player_y:
                # ê¸´ê¸‰ íšŒí”¼
                if player_y >= HEIGHT - player_size - 10:
                    return 'jump'
        
        # ìš©ì•” íšŒí”¼ (ìµœìš°ì„ )
        if lava.get('state') == 'active':
            lava_zone_x = lava.get('zone_x', 0)
            lava_zone_width = lava.get('zone_width', 320)
            lava_zone_end = lava_zone_x + lava_zone_width
            
            if player_x + player_size > lava_zone_x and player_x < lava_zone_end:
                if player_center_x < WIDTH / 2:
                    return 'left'
                else:
                    return 'right'
        
        # PPO ëª¨ë¸ ì˜ì‚¬ê²°ì •
        ppo_action = self.ppo_strategy.make_decision(game_state)
        if ppo_action:
            return ppo_action
        
        # ìš©ì•” ê²½ê³  íšŒí”¼
        if lava.get('state') == 'warning':
            lava_zone_x = lava.get('zone_x', 0)
            lava_zone_width = lava.get('zone_width', 320)
            lava_zone_end = lava_zone_x + lava_zone_width
            
            if player_x + player_size > lava_zone_x - 50 and player_x < lava_zone_end + 50:
                if player_center_x < WIDTH / 2:
                    return 'left'
                else:
                    return 'right'
        
        return None


class Level4Strategy(AIStrategy):
    """
    Level 4 (Expert) - í’€ ì•™ìƒë¸”
    
    ì „ëµ:
    - PPO + íœ´ë¦¬ìŠ¤í‹± + ìš©ì•”/ë³„ ì „ëµ
    - ëª¨ë“  ìš”ì†Œ ê³ ë ¤
    """
    
    def __init__(self, ppo_model_path: Optional[str] = None, dqn_model_path: Optional[str] = None):
        super().__init__(level=4, name="Expert")
        self.level3_strategy = Level3Strategy(model_path=ppo_model_path)
    
    def make_decision(self, game_state: Dict[str, Any]) -> Optional[str]:
        """Level 3 ì „ëµ + ì¶”ê°€ ìµœì í™”"""
        return self.level3_strategy.make_decision(game_state)


# ============================================================================
# AI Level Manager
# ============================================================================

class AILevelManager:
    """AI ë‚œì´ë„ ë ˆë²¨ ê´€ë¦¬ì"""
    
    def __init__(self, ppo_model_path: Optional[str] = None, dqn_model_path: Optional[str] = None):
        """
        ì´ˆê¸°í™”
        
        Args:
            ppo_model_path: PPO ëª¨ë¸ ê²½ë¡œ (Level 2, 3, 4ì—ì„œ ì‚¬ìš©)
            dqn_model_path: DQN ëª¨ë¸ ê²½ë¡œ (ì„ íƒì )
        """
        self.ppo_model_path = ppo_model_path
        self.dqn_model_path = dqn_model_path
        
        self.strategies = {
            1: Level1Strategy(),
            2: Level2Strategy(model_path=ppo_model_path),
            3: Level3Strategy(model_path=ppo_model_path),
            4: Level4Strategy(ppo_model_path=ppo_model_path, dqn_model_path=dqn_model_path)
        }
        self.current_level = 2  # ê¸°ë³¸ê°’: Level 2 (PPO)
        
        print(f"ğŸ¤– AI Level Manager ì´ˆê¸°í™”")
        print(f"   - Level 1: Easy (íœ´ë¦¬ìŠ¤í‹±)")
        print(f"   - Level 2: Medium (PPO)")
        print(f"   - Level 3: Hard (PPO + íœ´ë¦¬ìŠ¤í‹±)")
        print(f"   - Level 4: Expert (ì•™ìƒë¸”)")
    
    def set_level(self, level: int):
        """ë‚œì´ë„ ë ˆë²¨ ì„¤ì •"""
        if level not in self.strategies:
            print(f"âš ï¸ Invalid level: {level}. Using default (2).")
            level = 2
        self.current_level = level
    
    def make_decision(self, game_state: Dict[str, Any]) -> Optional[str]:
        """í˜„ì¬ ë ˆë²¨ì˜ ì „ëµìœ¼ë¡œ ì˜ì‚¬ê²°ì •"""
        strategy = self.strategies[self.current_level]
        return strategy.make_decision(game_state)
    
    def get_level_info(self) -> Dict[str, Any]:
        """í˜„ì¬ ë ˆë²¨ ì •ë³´ ë°˜í™˜"""
        strategy = self.strategies[self.current_level]
        return {
            'level': self.current_level,
            'name': strategy.name,
            'description': f"Level {self.current_level}: {strategy.name}"
        }


# ============================================================================
# Legacy Support (AIModule class)
# ============================================================================

class AIDecisionResult:
    """AI ì˜ì‚¬ê²°ì • ê²°ê³¼ (ë ˆê±°ì‹œ í˜¸í™˜)"""
    
    def __init__(self, action: str, confidence: float = 0.5, reasoning: str = ""):
        self.action = action
        self.confidence = confidence
        self.reasoning = reasoning
        self.timestamp = time.time()
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'action': self.action,
            'confidence': self.confidence,
            'reasoning': self.reasoning,
            'timestamp': self.timestamp
        }


class AIModule:
    """
    AI ëª¨ë“ˆ (ë ˆê±°ì‹œ í˜¸í™˜ìš©)
    
    ìƒˆ ì½”ë“œì—ì„œëŠ” AILevelManager ì‚¬ìš© ê¶Œì¥
    """
    
    def __init__(self, model_path: Optional[str] = None, algorithm: str = "PPO"):
        self.level_manager = AILevelManager(ppo_model_path=model_path)
        self.level_manager.set_level(2)  # Level 2 (PPO) ì‚¬ìš©
    
    def make_decision(self, game_state: Dict[str, Any]) -> AIDecisionResult:
        action = self.level_manager.make_decision(game_state)
        if action is None:
            action = 'stay'
        return AIDecisionResult(action=action)


# ============================================================================
# Test
# ============================================================================

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ê²Œì„ ìƒíƒœ
    test_state = {
        'player': {
            'x': 480,
            'y': 670,
            'vy': 0,
            'size': 50,
            'health': 100
        },
        'obstacles': [
            {'type': 'meteor', 'x': 500, 'y': 200, 'size': 50, 'vx': 0, 'vy': 5},
            {'type': 'star', 'x': 300, 'y': 400, 'size': 30, 'vx': 0, 'vy': 3}
        ],
        'lava': {
            'state': 'inactive',
            'zone_x': 0,
            'zone_width': 320,
            'height': 120
        },
        'score': 50,
        'frame': 100
    }
    
    # AI Level Manager í…ŒìŠ¤íŠ¸
    ai_manager = AILevelManager(ppo_model_path="models/rl/ppo_agent.pt")
    
    for level in [1, 2, 3, 4]:
        ai_manager.set_level(level)
        action = ai_manager.make_decision(test_state)
        info = ai_manager.get_level_info()
        print(f"Level {level} ({info['name']}): Action = {action}")
